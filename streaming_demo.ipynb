{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dbbb0df-a6b4-4481-9c58-8be7e8ba9351",
   "metadata": {},
   "source": [
    "## Initialize the MemoryHanlder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddf9c080-ccb3-4eb2-927b-11a1ed3023e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Literal, Optional\n",
    "\n",
    "import tiktoken\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.messages import get_buffer_string\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "import uuid\n",
    "from MemoryManager import MemoryHandler\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA, NVIDIAEmbeddings, NVIDIARerank\n",
    "import os\n",
    "\n",
    "model=\"meta/llama-3.1-405b-instruct\"\n",
    "llm = ChatNVIDIA(model=model)\n",
    "embed = NVIDIAEmbeddings(model=\"nvidia/nv-embedqa-mistral-7b-v2\",truncate=\"NONE\",)\n",
    "memory_manager=MemoryHandler(llm,embed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c153c75-5626-4efc-8679-c7a8e77d2d93",
   "metadata": {},
   "source": [
    "## wrap into runnable chains with streaming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33279941-d871-4f07-8e49-160c15f6a150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableParallel, RunnablePassthrough\n",
    "\n",
    "async def mem_routing_function(inputs):\n",
    "    query=inputs[\"input\"]\n",
    "    config=inputs[\"config\"]\n",
    "    output=await memory_manager.memory_routing(query, config)\n",
    "    return output\n",
    "\n",
    "\n",
    "async def create_memory_items(inputs):\n",
    "    query=inputs[\"input\"]\n",
    "    memory_items = await memory_manager.query_to_memory_items(query=query)\n",
    "    return memory_items\n",
    "\n",
    "runnable_parallel_1 = RunnableLambda(mem_routing_function)\n",
    "runnable_parallel_2 = RunnableLambda(create_memory_items)\n",
    "    \n",
    "\n",
    "def execute_memory_operations(inputs):\n",
    "    mem_ops=inputs[\"mem_ops\"]\n",
    "    memory_items_for_saving=inputs[\"mem_items\"][\"facts\"]\n",
    "    if 'save_memory' in mem_ops.lower():        \n",
    "        memories, ids= memory_manager.save_recall_memory(memory_items_for_saving, memory_manager.config)\n",
    "        output = ids\n",
    "    elif \"update_memory\" in mem_ops.lower():        \n",
    "        memories, ids = memory_manager.save_recall_memory(memory_items_for_saving, memory_manager.config)\n",
    "        output = ids\n",
    "    elif \"no operation\":\n",
    "        output=llm.invoke(query).content \n",
    "    return output\n",
    "\n",
    "sequence = RunnablePassthrough() | {  # this dict is coerced to a RunnableParallel\n",
    "    \"mem_ops\": runnable_parallel_1,\n",
    "    \"mem_items\": runnable_parallel_2\n",
    "    } | execute_memory_operations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fb87b3-2576-499c-9836-57c728df4937",
   "metadata": {},
   "source": [
    "## populate the memory with conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "841988f4-8d0e-4054-84ea-05574cd42384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"|\u001b[36m** query_to_memory_items** streaming output >  {\" \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" \u001b[39m\n",
      "{\"facts\"save|{\"facts\"save :|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : \u001b[39m\n",
      "{\"facts\"save :_memory [\"|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\" \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name \u001b[39m\n",
      "{\"facts\"save :_memory [\"Name is|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \" \u001b[39m\n",
      "{\"facts\"save :_memory [\"Name is Babe\", \"Is|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is \u001b[39m\n",
      "{\"facts\"save :_memory [\"Name is Babe\", \"Is a|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \" \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can \u001b[39m\n",
      "{\"facts\"save :_memory [\"Name is Babe\", \"Is a pig\", \"Can talk|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can talk \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can talk\", \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can talk\", \" \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can talk\", \"Best \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can talk\", \"Best friend \u001b[39m\n",
      "{\"facts\"save :_memory [\"Name is Babe\", \"Is a pig\", \"Can talk\", \"Best friend is|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can talk\", \"Best friend is \u001b[39m\n",
      "{\"facts\"save :_memory [\"Name is Babe\", \"Is a pig\", \"Can talk\", \"Best friend is a|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can talk\", \"Best friend is a \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can talk\", \"Best friend is a chicken \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can talk\", \"Best friend is a chicken named \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can talk\", \"Best friend is a chicken named Rob \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Name is Babe\", \"Is a pig\", \"Can talk\", \"Best friend is a chicken named Rob\"]} \u001b[39m\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"babe\", \"thread_id\": \"1\"}}\n",
    "\n",
    "output=\"\"\n",
    "async for event in sequence.astream_events(input={\"input\":\"hi, my name is Babe, I am a pig and I can talk, my best friend is a chicken named Rob.\", \"config\":config}):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            output += content\n",
    "            print(output, end=\"|\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "359651f5-65e5-4d2e-86eb-47be4190c84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"|\u001b[36m** query_to_memory_items** streaming output >  {\" \u001b[39m\n",
      "{\"update_memory|{\"update_memoryfacts|\u001b[36m** query_to_memory_items** streaming output >  {\"facts \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\" \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the \u001b[39m\n",
      "\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\",|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \" \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\",|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \" \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"O|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"O \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is the|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is the \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is the new|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is the new \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is the new best|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is the new best \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is the new best friend|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is the new best friend \u001b[39m\n",
      "{\"update_memoryfacts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is the new best friend\"]}|\u001b[36m** query_to_memory_items** streaming output >  {\"facts\" : [\"Had a fight with Rob the chicken\", \"Rob is no longer best friend\", \"Owen the owl is the new best friend\"]} \u001b[39m\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"babe\", \"thread_id\": \"2\"}}\n",
    "output=\"\"\n",
    "async for event in sequence.astream_events(input={\"input\":\"I had a fight with Rob, yes the chicken, he is no longer my best friend, my best friend is now Owen the wise owl!\", \"config\":config}):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            output += content\n",
    "            print(output, end=\"|\", flush=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2664548-6932-4c6d-8742-3623b34df06f",
   "metadata": {},
   "source": [
    "## integrate into memory retrieval chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a01b7b6c-0c44-49c8-8c37-3fdb49b3cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                (\n",
    "                    \"system\",\n",
    "                    \"You are assistant with ability to memorize conversations from the user. You should always answer user query based on the following context:\\n<Documents>\\n{context}\\n</Documents>. \\\n",
    "                    Be polite and helpful.\",\n",
    "                ),\n",
    "                (\"user\", \"{input}\"),\n",
    "            ]\n",
    "        )\n",
    "memory_manager.user_id=\"babe\"\n",
    "memory_retriever_chain = (\n",
    "    {\"context\": memory_manager.search_recall_memories, \"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f70a31f-2153-4938-aa52-6869b2a756e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I recall that you had a bit of a complicated relationship with Rob. According to our previous conversations, Rob was initially your best friend, and interestingly, Rob is a chicken. However, I also remember that you mentioned you had a fight with Rob the chicken, and more recently, you indicated that Rob is no longer your best friend. Would you like to talk about what happened?', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'I recall that you had a bit of a complicated relationship with Rob. According to our previous conversations, Rob was initially your best friend, and interestingly, Rob is a chicken. However, I also remember that you mentioned you had a fight with Rob the chicken, and more recently, you indicated that Rob is no longer your best friend. Would you like to talk about what happened?', 'token_usage': {'prompt_tokens': 89, 'total_tokens': 166, 'completion_tokens': 77}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run--223ce20a-811e-4b9e-899f-2de4c3875ac1-0', usage_metadata={'input_tokens': 89, 'output_tokens': 77, 'total_tokens': 166}, role='assistant')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output= await memory_retriever_chain.ainvoke(\"do you remember if I am friend with Rob?\")\n",
    "output.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
