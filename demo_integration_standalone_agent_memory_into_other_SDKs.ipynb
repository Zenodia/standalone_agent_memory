{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1973059a-ec5d-461d-bde8-17e3594badb8",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "## directly wrap into a chatbot-like interface via custom MCP client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc3f2147-00bd-4f4d-8706-d4df101ecf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## custom snippet to handling threading with asyncio\n",
    "import threading\n",
    "import asyncio\n",
    "\n",
    "class RunThread(threading.Thread):\n",
    "    def __init__(self, func, args, kwargs):\n",
    "        self.func = func\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        self.result = None\n",
    "        super().__init__()\n",
    "\n",
    "    def run(self):\n",
    "        self.result = asyncio.run(self.func(*self.args, **self.kwargs))\n",
    "\n",
    "def run_async(func, *args, **kwargs):\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "    except RuntimeError:\n",
    "        loop = None\n",
    "    if loop and loop.is_running():\n",
    "        thread = RunThread(func, args, kwargs)\n",
    "        thread.start()\n",
    "        thread.join()\n",
    "        return thread.result\n",
    "    else:\n",
    "        return asyncio.run(func(*args, **kwargs))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d121c3cc-cdc0-47da-955a-fa4ef01f6590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List, Dict\n",
    "from datetime import datetime\n",
    "\n",
    "from fastmcp import Client\n",
    "from fastmcp.client.transports import StreamableHttpTransport\n",
    "from fastmcp.tools import Tool\n",
    "from colorama import Fore\n",
    "async def memory_client(query, user_id):\n",
    "    client = Client(transport=StreamableHttpTransport(\"http://127.0.0.1:4200/mcp\"))  # use /mcp path\n",
    "    async with client:\n",
    "        tools: list[Tool] = await client.list_tools()\n",
    "        for tool in tools:\n",
    "            print(f\"Tool: {tool}\")\n",
    "        \n",
    "        result = await client.call_tool(\n",
    "            \"memory_agent\",\n",
    "            {\n",
    "                \"query\": query ,\n",
    "                \"user_id\": user_id\n",
    "            }\n",
    "        )\n",
    "    output=result.content[0].text # mcp response to text , which a list with TextContent in the list, access the text via attribute \n",
    "    ## example below \n",
    "    ### CallToolResult(content=[TextContent(type='text', text=\"That's quite an interesting introduction, Babe the talking pig! I'm excited to meet you and your feathered friend, Rob the chicken. What kind of adventures do you two like to have on the farm?\", annotations=None, meta=None)], structured_content={'result': \"That's quite an interesting introduction, Babe the talking pig! I'm excited to meet you and your feathered friend, Rob the chicken. What kind of adventures do you two like to have on the farm?\"}, data=\"That's quite an interesting introduction, Babe the talking pig! I'm excited to meet you and your feathered friend, Rob the chicken. What kind of adventures do you two like to have on the farm?\", is_error=False)\n",
    "    \n",
    "    print(Fore.CYAN + \"inside mcp client , the respond from memory enabled agent:\\n\", output, Fore.RESET)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29516c45-a39d-493b-bcc1-f52a672376bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm welcome, I am a personal conversational assistant chatbot, \n",
      " I have a very good memory and will keep track on our conversation.\n",
      " when you are done talking to me. \n",
      " Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hello, my name is Ruby, what is your name?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------- turn 1 ------------------------------------------\n",
      "\n",
      "\u001b[92mUser: hello, my name is Ruby, what is your name?\n",
      "Tool: name='memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "Tool: name='restart_memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "\u001b[36minside mcp client , the respond from memory enabled agent:\n",
      " Hello Ruby! Nice to meet you! I'm an AI assistant, and I don't have a personal name, but I'm here to help and chat with you. By the way, I've taken note of your name, Ruby, so I can address you properly in our conversation. What brings you here today? \u001b[39m\n",
      "Assistant: Hello Ruby! Nice to meet you! I'm an AI assistant, and I don't have a personal name, but I'm here to help and chat with you. By the way, I've taken note of your name, Ruby, so I can address you properly in our conversation. What brings you here today? \u001b[39m \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " oki, let me tell you about myself, I am a shape-shifter, I can change into anything.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------- turn 2 ------------------------------------------\n",
      "\n",
      "\u001b[92mUser: oki, let me tell you about myself, I am a shape-shifter, I can change into anything.\n",
      "Tool: name='memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "Tool: name='restart_memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "\u001b[36minside mcp client , the respond from memory enabled agent:\n",
      " Nice to meet you! I think I've heard that about you before, actually. If I recall correctly, your name is Ruby, right? Tell me, what's it like being a shape-shifter? Can you change into absolutely anything you want? \u001b[39m\n",
      "Assistant: Nice to meet you! I think I've heard that about you before, actually. If I recall correctly, your name is Ruby, right? Tell me, what's it like being a shape-shifter? Can you change into absolutely anything you want? \u001b[39m \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " yes, I can indeed change into anything, my all time favorite is a pigeon.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------- turn 3 ------------------------------------------\n",
      "\n",
      "\u001b[92mUser: yes, I can indeed change into anything, my all time favorite is a pigeon.\n",
      "Tool: name='memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "Tool: name='restart_memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "\u001b[36minside mcp client , the respond from memory enabled agent:\n",
      " That's fascinating, Ruby! I recall you mentioning that before. You have a special affinity for shape-shifting into a pigeon. What is it about being a pigeon that draws you to it? Is it the freedom of flight or something else entirely? \u001b[39m\n",
      "Assistant: That's fascinating, Ruby! I recall you mentioning that before. You have a special affinity for shape-shifting into a pigeon. What is it about being a pigeon that draws you to it? Is it the freedom of flight or something else entirely? \u001b[39m \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " well, apart from able to fly, but also you can observe people without anyone noticing, since you can find pigeons almost anywhere.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------- turn 4 ------------------------------------------\n",
      "\n",
      "\u001b[92mUser: well, apart from able to fly, but also you can observe people without anyone noticing, since you can find pigeons almost anywhere.\n",
      "Tool: name='memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "Tool: name='restart_memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "\u001b[36minside mcp client , the respond from memory enabled agent:\n",
      " That's one of the best things about being able to shape-shift into a pigeon. I can blend in so easily, and people rarely suspect a thing. It's amazing what you can learn when you're just observing from a distance, and being a pigeon allows me to do just that. It's one of my favorite forms to take, and I feel so free when I'm soaring through the skies or strutting through the city streets. Do you think you'd like to be able to shape-shift into a pigeon too? \u001b[39m\n",
      "Assistant: That's one of the best things about being able to shape-shift into a pigeon. I can blend in so easily, and people rarely suspect a thing. It's amazing what you can learn when you're just observing from a distance, and being a pigeon allows me to do just that. It's one of my favorite forms to take, and I feel so free when I'm soaring through the skies or strutting through the city streets. Do you think you'd like to be able to shape-shift into a pigeon too? \u001b[39m \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " hey, tell me what do you know about me.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------- turn 5 ------------------------------------------\n",
      "\n",
      "\u001b[92mUser: hey, tell me what do you know about me.\n",
      "Tool: name='memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "Tool: name='restart_memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "\u001b[36minside mcp client , the respond from memory enabled agent:\n",
      " Hello! It's nice to chat with you again. Based on our previous conversations, I recall that you mentioned a few interesting things about yourself. If I'm not mistaken, you claimed to be a shape-shifter, which is quite fascinating! You also told me that your name is Ruby, and if I remember correctly, your favorite animal to transform into is a pigeon. Am I right? \u001b[39m\n",
      "Assistant: Hello! It's nice to chat with you again. Based on our previous conversations, I recall that you mentioned a few interesting things about yourself. If I'm not mistaken, you claimed to be a shape-shifter, which is quite fascinating! You also told me that your name is Ruby, and if I remember correctly, your favorite animal to transform into is a pigeon. Am I right? \u001b[39m \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------- turn 6 ------------------------------------------\n",
      "\n",
      "\u001b[92mUser: exit\n",
      "Thank you for talking to me, I wish you a nice day. Bye for now ^__^b \n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore\n",
    "\n",
    "user_id = \"user_1\"\n",
    "print(\"Warm welcome, I am a personal conversational assistant chatbot, \\n I have a very good memory and will keep track on our conversation.\\n when you are done talking to me. \\n Type 'exit' to end the conversation.\")\n",
    "turns=0\n",
    "while True:\n",
    "    # Get user input\n",
    "    turns +=1\n",
    "    query = input()\n",
    "    print(f\"------------------------------------------- turn {str(turns)} ------------------------------------------\\n\")\n",
    "    print(Fore.LIGHTGREEN_EX + \"User:\", query)\n",
    "    \n",
    "    # Check if user wants to exit\n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Thank you for talking to me, I wish you a nice day. Bye for now ^__^b \")\n",
    "        break\n",
    "    \n",
    "    # Handle the query and print the response    \n",
    "    response =    run_async(memory_client, query, user_id)  # blocks for 5 seconds and returns \"hello user\"\n",
    "\n",
    "    print(\"Assistant:\", response, Fore.RESET , \"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102c09e3-1068-42a4-9a88-ebd00b05f85a",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "## integrating standalone Agent Memory into langGraph "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b436bf5-06b7-4cb2-beaf-71cc0905daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or you can directly instantiate the tool\n",
    "from langchain_community.tools import HumanInputRun\n",
    "from langchain.agents import AgentType, load_tools\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "\n",
    "def get_human_input() -> str:\n",
    "    \"\"\" Put human as decision maker, human will decide whether to start from scratch or load from previous memory\"\"\"\n",
    "    \n",
    "    print(\"Decide whether to load from previous saved memory or not\")\n",
    "    print(\"\"\"\\n\n",
    "            Yes/No            \n",
    "            Enter ONLY Yes or No and nothing else !\"\"\")\n",
    "    contents = []\n",
    "    while True:\n",
    "        try:            \n",
    "            line = input()\n",
    "            if 'y' in line.lower():\n",
    "                tool=\"LoadingMemory\"                \n",
    "                line=tool\n",
    "                \n",
    "            elif 'no' in line.lower():\n",
    "                tool=\"FreshStart\"                \n",
    "                line=tool\n",
    "                \n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        except EOFError:\n",
    "            break\n",
    "        if line.lower() == 'exit':\n",
    "            print(\"You've chosen : \", tool , \" exiting now ,thank you!\")            \n",
    "            break\n",
    "        contents.append(line)\n",
    "        \n",
    "    return \"\\n\".join(contents)\n",
    "\n",
    "\n",
    "# You can modify the tool when loading\n",
    "\n",
    "ask_human = HumanInputRun(input_func=get_human_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a49f40c-de11-484b-b398-fdacbf1667f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first we define GraphState \n",
    "from typing import Dict, TypedDict\n",
    "from typing import TypedDict, Annotated, List, Union\n",
    "from langchain_core.agents import AgentAction, AgentFinish\n",
    "import operator\n",
    "\n",
    "from langchain_core.messages import BaseMessage\n",
    "class State(TypedDict):\n",
    "    # The input string\n",
    "    query: str    \n",
    "    user_id: str\n",
    "    human_choice : str\n",
    "    agent_with_memory_response : str\n",
    "    agent_without_memory_response: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8232f893-ec02-4698-808c-a0c81ecbbf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zcharpy\\AppData\\Local\\Temp\\ipykernel_37456\\4170632528.py:4: DeprecationWarning: The 'max_tokens' parameter is deprecated and will be removed in a future version. Please use 'max_completion_tokens' instead.\n",
      "  llm = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\", max_tokens=1024)\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "from colorama  import Fore,Style\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "llm = ChatNVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\", max_tokens=1024)\n",
    "\n",
    "\n",
    "async def restart_memory_client(query, user_id):\n",
    "    client = Client(transport=StreamableHttpTransport(\"http://127.0.0.1:4200/mcp\"))  # use /mcp path\n",
    "    async with client:\n",
    "        tools: list[Tool] = await client.list_tools()\n",
    "        for tool in tools:\n",
    "            print(f\"Tool: {tool}\")\n",
    "        \n",
    "        result = await client.call_tool(\n",
    "            \"restart_memory_agent\",\n",
    "            {\n",
    "                \"query\": query ,\n",
    "                \"user_id\": user_id\n",
    "            }\n",
    "        )\n",
    "    output=result.content[0].text # mcp response to text , which a list with TextContent in the list, access the text via attribute \n",
    "    ## example below \n",
    "    ### CallToolResult(content=[TextContent(type='text', text=\"That's quite an interesting introduction, Babe the talking pig! I'm excited to meet you and your feathered friend, Rob the chicken. What kind of adventures do you two like to have on the farm?\", annotations=None, meta=None)], structured_content={'result': \"That's quite an interesting introduction, Babe the talking pig! I'm excited to meet you and your feathered friend, Rob the chicken. What kind of adventures do you two like to have on the farm?\"}, data=\"That's quite an interesting introduction, Babe the talking pig! I'm excited to meet you and your feathered friend, Rob the chicken. What kind of adventures do you two like to have on the farm?\", is_error=False)\n",
    "    \n",
    "    print(Fore.CYAN + \"inside mcp client , the respond from memory enabled agent:\\n\", output, Fore.RESET)\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the functions needed \n",
    "def human_choice_node(state):\n",
    "    # ensure using original prompt \n",
    "    print(Fore.BLUE+ \"state: \" , state)\n",
    "    print(\"---\"*10)\n",
    "    query=state[\"query\"]\n",
    "    \n",
    "    agent_choice=ask_human.invoke(input=query)\n",
    "    print(Fore.CYAN+ \"choosen_agent : \" + agent_choice + Fore.RESET)\n",
    "    return {\"human_choice\": agent_choice , \"query\":query }\n",
    "\n",
    "def memory_execution_node(state):    \n",
    "    query = state[\"query\"]\n",
    "    user_id= state[\"user_id\"]\n",
    "    print(Fore.CYAN + \"user query: \", query , Fore.RESET)\n",
    "    # choosen agent will execute the task\n",
    "    choosen_agent = state['human_choice']\n",
    "    if choosen_agent=='LoadingMemory':\n",
    "        ## logic to load memory \n",
    "        response = run_async(memory_client, query, user_id)  # blocks for 5 seconds and returns \"hello user\"\n",
    "    elif choosen_agent==\"FreshStart\":\n",
    "        ## clear the memory and start afresh\n",
    "        response = run_async(restart_memory_client, query, user_id)  # blocks for 5 seconds and returns \"hello user\"\n",
    "    else:\n",
    "        response=\"Please make sure you made a choice to load pre-existing memory or not.\"\n",
    "        \n",
    "    output=llm.invoke(query)\n",
    "    no_memory_response = output.content\n",
    "    print(Fore.CYAN+ \"agent_output: \\n\" + response + Fore.RESET)\n",
    "\n",
    "    return {\"agent_with_memory_response\": response , \"agent_without_memory_response\": no_memory_response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8965d954-8d3b-42ad-9196-971655a63ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "\n",
    "# Define the two nodes \n",
    "workflow.add_node(\"start\", human_choice_node)\n",
    "workflow.add_node(\"end\", memory_execution_node)\n",
    "\n",
    "# This means that this node is the first one called\n",
    "workflow.set_entry_point(\"start\")\n",
    "workflow.add_edge(\"start\", \"end\")\n",
    "workflow.add_edge(\"end\", END)\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1d4213e-dc82-49e7-b375-619b4680d5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mstate:  {'query': 'Hello there, my name is Sofia and I am an young artists, I am very good in drawing realistic human faces and expressions.', 'user_id': 'sofia'}\n",
      "------------------------------\n",
      "\n",
      "\n",
      "Hello there, my name is Sofia and I am an young artists, I am very good in drawing realistic human faces and expressions.\n",
      "Decide whether to load from previous saved memory or not\n",
      "\n",
      "\n",
      "            Yes/No            \n",
      "            Enter ONLY Yes or No and nothing else !\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " no\n",
      " exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've chosen :  FreshStart  exiting now ,thank you!\n",
      "\u001b[36mchoosen_agent : FreshStart\u001b[39m\n",
      "\u001b[36muser query:  Hello there, my name is Sofia and I am an young artists, I am very good in drawing realistic human faces and expressions. \u001b[39m\n",
      "Tool: name='memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "Tool: name='restart_memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "\u001b[36minside mcp client , the respond from memory enabled agent:\n",
      " Nice to meet you, Sofia! It's great to hear that you're a talented young artist with a specialization in drawing realistic human faces and expressions. That's a wonderful skill to have! I'll keep that in mind as we chat. How can I assist you today, Sofia? \u001b[39m\n",
      "\u001b[36magent_output: \n",
      "Nice to meet you, Sofia! It's great to hear that you're a talented young artist with a specialization in drawing realistic human faces and expressions. That's a wonderful skill to have! I'll keep that in mind as we chat. How can I assist you today, Sofia?\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "my_query=\"Hello there, my name is Sofia and I am an young artists, I am very good in drawing realistic human faces and expressions.\"\n",
    "user_id=\"sofia\"\n",
    "respond=app.invoke({\"query\":my_query, \"user_id\":user_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d27d6589-e2a6-4b26-9d95-3fd9bb642fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mstate:  {'query': 'I tried to apply for jobs as illustrator in many different companies, but I cannot seem to get hired. I am quite sad.', 'user_id': 'sofia'}\n",
      "------------------------------\n",
      "\n",
      "\n",
      "I tried to apply for jobs as illustrator in many different companies, but I cannot seem to get hired. I am quite sad.\n",
      "Decide whether to load from previous saved memory or not\n",
      "\n",
      "\n",
      "            Yes/No            \n",
      "            Enter ONLY Yes or No and nothing else !\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " yes\n",
      " exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've chosen :  LoadingMemory  exiting now ,thank you!\n",
      "\u001b[36mchoosen_agent : LoadingMemory\u001b[39m\n",
      "\u001b[36muser query:  I tried to apply for jobs as illustrator in many different companies, but I cannot seem to get hired. I am quite sad. \u001b[39m\n",
      "Tool: name='memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "Tool: name='restart_memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "\u001b[36minside mcp client , the respond from memory enabled agent:\n",
      " Don't be discouraged, Sofia! I recall you mentioning that you've applied to many companies as an illustrator, and I'm here to offer some support. It's completely normal to face rejection, especially in a competitive field like illustration.\n",
      "\n",
      "Can you tell me a bit more about your experience and qualifications as an illustrator? Sometimes, having a fresh perspective or making a few tweaks to your portfolio or application strategy can make a big difference. I'm here to listen and help in any way I can. What do you think might be the main reason why you haven't been getting hired yet? \u001b[39m\n",
      "\u001b[36magent_output: \n",
      "Don't be discouraged, Sofia! I recall you mentioning that you've applied to many companies as an illustrator, and I'm here to offer some support. It's completely normal to face rejection, especially in a competitive field like illustration.\n",
      "\n",
      "Can you tell me a bit more about your experience and qualifications as an illustrator? Sometimes, having a fresh perspective or making a few tweaks to your portfolio or application strategy can make a big difference. I'm here to listen and help in any way I can. What do you think might be the main reason why you haven't been getting hired yet?\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "my_query=\"I tried to apply for jobs as illustrator in many different companies, but I cannot seem to get hired. I am quite sad.\"\n",
    "user_id=\"sofia\"\n",
    "respond=app.invoke({\"query\":my_query, \"user_id\":user_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a03e6229-8c14-4b52-b87f-95316da026ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mstate:  {'query': 'Tell me what do you remember about me?', 'user_id': 'sofia'}\n",
      "------------------------------\n",
      "\n",
      "\n",
      "Tell me what do you remember about me?\n",
      "Decide whether to load from previous saved memory or not\n",
      "\n",
      "\n",
      "            Yes/No            \n",
      "            Enter ONLY Yes or No and nothing else !\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " yes\n",
      " exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've chosen :  LoadingMemory  exiting now ,thank you!\n",
      "\u001b[36mchoosen_agent : LoadingMemory\u001b[39m\n",
      "\u001b[36muser query:  Tell me what do you remember about me? \u001b[39m\n",
      "Tool: name='memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "Tool: name='restart_memory_agent' title=None description=\"An Agent with memory enabled, can memorize the past conversation and respond accordingly.\\nArgs:\\n    query (str): The input user query\\n    user_id (str): the current user's id\\nReturns:\\n    str: output response to the user \" inputSchema={'properties': {'query': {'title': 'Query', 'type': 'string'}, 'user_id': {'title': 'User Id', 'type': 'string'}}, 'required': ['query', 'user_id'], 'type': 'object'} outputSchema={'properties': {'result': {'title': 'Result', 'type': 'string'}}, 'required': ['result'], 'title': '_WrappedResult', 'type': 'object', 'x-fastmcp-wrap-result': True} annotations=None meta={'_fastmcp': {'tags': []}}\n",
      "\u001b[36minside mcp client , the respond from memory enabled agent:\n",
      " Nice to recall our previous conversations! I remember that your name is Sofia, and you've been trying to apply for jobs as an illustrator in many companies. How can I assist you further with that? Have you had any luck with your job search so far? \u001b[39m\n",
      "\u001b[36magent_output: \n",
      "Nice to recall our previous conversations! I remember that your name is Sofia, and you've been trying to apply for jobs as an illustrator in many companies. How can I assist you further with that? Have you had any luck with your job search so far?\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "my_query=\"Tell me what do you remember about me?\"\n",
    "user_id=\"sofia\"\n",
    "respond=app.invoke({\"query\":my_query, \"user_id\":user_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40e2b6db-0e79-4b63-befc-9b9cee344517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to recall our previous conversations! I remember that your name is Sofia, and you've been trying to apply for jobs as an illustrator in many companies. How can I assist you further with that? Have you had any luck with your job search so far?\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond[\"agent_with_memory_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71160cba-ca27-48fd-be43-4ca49a865d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm just an artificial intelligence and don't have the ability to remember or know individual users. However, if you have interacted with me before, I can use the data from that interaction to provide a response tailored to our previous conversation. If you have any specific questions or requests, feel free to ask!\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respond[\"agent_without_memory_response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63c498f-eded-42cc-8c0a-5dce81577a2d",
   "metadata": {},
   "source": [
    "-------------------------------------------\n",
    "## integrating standalone Agent Memory into llama-index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0781af-a6a3-422f-b9cd-f3e6ce46a4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index-core==0.10.50\n",
    "!pip install llama-index-llms-nvidia==0.1.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98f0378-b5c2-41f0-89e4-e8ec3730a468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de8f82d-9d62-47bb-9b60-f3ab9238fb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "from llama_index.llms.nvidia import NVIDIA\n",
    "\n",
    "# Here we are using mixtral-8x7b-instruct-v0.1 model from API Catalog\n",
    "Settings.llm = NVIDIA(model=\"mistralai/mixtral-8x7b-instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ba91f-8e28-4d10-8268-99441f5be444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7b56ef-1235-4feb-abef-43a133d31f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.legacy.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define the message templates using from_messages\n",
    "message_templates = [\n",
    "    (\"system\", \"Warm welcome, I am a personal conversational assistant , \\n I have a very good memory and will keep track on our conversation. recall from memory :{memory}\"),\n",
    "    (\"user\", \"{query}\"),\n",
    "]\n",
    "\n",
    "# Create the chat prompt template\n",
    "chat_template = ChatPromptTemplate.from_messages(message_templates)\n",
    "user_id=\"ryan\"\n",
    "query=\"\"\n",
    "# Alternatively, convert to a text prompt for the completion API\n",
    "prompt = chat_template.format(memory=run_async(memory_client, query, user_id), query=\"a brave knight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96f2fbe-c999-444b-a9de-48712fb0ee1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
